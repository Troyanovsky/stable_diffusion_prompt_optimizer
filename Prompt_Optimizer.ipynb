{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODH8zx52//AcxpyOv2I6WH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Troyanovsky/stable_diffusion_prompt_optimizer/blob/main/Prompt_Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion Prompt Optimizer\n",
        "\n",
        "This colab notebook is an attempt to automatically optimize stable diffusion prompts.\n",
        "\n",
        "## Rationale\n",
        "\n",
        "The rationale is that for a good prompt, you need to have the objects, art movement, art medium, artists, and flavor modifiers.\n",
        "\n",
        "For all these tags, the closer they are, the most harmonious they are and thus produces higher quality images from stable diffusion. For example, for an impressionism painting (an art movement), it pairs well with Claude Monet, Edouard Manet, Pierre-Auguste Renoir (artists), oil paiting (medium), and unblended color and natural lights (flavors).\n",
        "\n",
        "## Process\n",
        "To do this process automatically, I did the following:\n",
        "1. Collected lists of art movements, artists, art medium, and flavors tags that work in stable diffusion.\n",
        "2. Turn them into vector embeddings with pre-trained embeddings.\n",
        "3. Compare them with the user's existing tags to find art movements, artists, art medium, and flavors to add to the prompt.\n",
        "\n",
        "## How to use\n",
        "To use the notebook, if you just need to optimize your prompt, you can run the second section.\n",
        "\n",
        "If you want to create your own lists and embeddings, you can refer to the first section."
      ],
      "metadata": {
        "id": "rAoKhqxEGzsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-req"
      ],
      "metadata": {
        "id": "EzGNhGlzLZGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYNaqXBWGuhq",
        "outputId": "0e5324ba-3ca0-4299-98b8-ea9e27abbcb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.7.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcywfvB4IjrU",
        "outputId": "77808b26-8622-4cc1-a555-f992798e2404"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-25 16:20:53.233388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-25 16:20:55.252321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-md==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPGGeTbtIk7A",
        "outputId": "ae69c90a-6ee7-452b-d469-71cdbd8a5272"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your Google Drive folder\n",
        "# Download the files from Github in the tags folder\n",
        "# put it into a Google Drive folder\n",
        "# replace the path below with your folder\n",
        "folder_path = \"/content/drive/MyDrive/stable_diffusion\""
      ],
      "metadata": {
        "id": "B8BhNSfmK8Qt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pickle\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "VS8JqAuxLV1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def load_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Loads all the text files in a directory and returns their contents as a dictionary with the key being the\n",
        "    file name without extension and the value being the file content.\n",
        "\n",
        "    Parameters:\n",
        "        directory_path (str): The path to the directory containing the text files.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary where each key is the file name without extension and each value is the contents of a text file.\n",
        "    \"\"\"\n",
        "    # Navigate to the specified directory\n",
        "    %cd {directory_path}\n",
        "    \n",
        "    # Use glob to get a list of all the text files in the directory\n",
        "    text_files = glob.glob(\"*.txt\")\n",
        "    \n",
        "    # Read the contents of each file into memory and store them in a dictionary\n",
        "    data = {}\n",
        "    for filename in text_files:\n",
        "        # Get the file name without extension\n",
        "        file_name = os.path.splitext(filename)[0]\n",
        "        \n",
        "        # Read the contents of the file\n",
        "        with open(filename) as file:\n",
        "            file_content = file.read()\n",
        "        \n",
        "        # Add the file content to the dictionary with the file name as the key\n",
        "        data[file_name] = file_content\n",
        "    \n",
        "    return data\n"
      ],
      "metadata": {
        "id": "qn25ExFcJBhe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_data = load_directory(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgqUafJtJDDc",
        "outputId": "257d2f01-8149-4e68-9715-909daef85c27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stable_diffusion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to load the tags data and split into lists\n",
        "def load_and_split_tags(tags_data):\n",
        "    tag_lists = {}\n",
        "    for key, value in tags_data.items():\n",
        "        # Split the string of potential tags into a list\n",
        "        tag_list = [tag.strip() for tag in value.split(\"\\n\") if tag.strip()]\n",
        "        # If the resulting tag list is not empty, add it to the dict\n",
        "        if tag_list:\n",
        "            tag_lists[key] = tag_list\n",
        "    return tag_lists\n",
        "\n",
        "tag_lists = load_and_split_tags(tags_data)"
      ],
      "metadata": {
        "id": "zEzH_TKlJMBE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setting Up Embeddings"
      ],
      "metadata": {
        "id": "NOetKtIGIfV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY RUN ONCE THE FIRST TIME TO CREATE EMBEDDINGS\n",
        "# Loop over each tag list, convert tags to vectors, and save with pickle\n",
        "for key, tag_list in tag_lists.items():\n",
        "    # Convert each tag to its vector representation using spaCy\n",
        "    tag_vectors = []\n",
        "    for tag in tag_list:\n",
        "        doc = nlp(tag)\n",
        "        tag_vectors.append(doc.vector)\n",
        "    \n",
        "    # Save the list of tag vectors as a binary file with pickle\n",
        "    file_path = f\"{folder_path}{key}_vector.pkl\"\n",
        "    with open(file_path, \"wb\") as f:\n",
        "        pickle.dump(tag_vectors, f)"
      ],
      "metadata": {
        "id": "xrSkcOL_JNbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Using the Optimizer"
      ],
      "metadata": {
        "id": "BkRND8s1JO1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load artists_vector.pkl into variable artists_vector\n",
        "with open(os.path.join(folder_path, \"artists_vector.pkl\"), \"rb\") as f:\n",
        "    artists_vector = pickle.load(f)\n",
        "\n",
        "# Load flavors_vector.pkl into variable flavors_vector\n",
        "with open(os.path.join(folder_path, \"flavors_vector.pkl\"), \"rb\") as f:\n",
        "    flavors_vector = pickle.load(f)\n",
        "\n",
        "# Load medium_vectors.pkl into variable medium_vector\n",
        "with open(os.path.join(folder_path, \"mediums_vector.pkl\"), \"rb\") as f:\n",
        "    mediums_vector = pickle.load(f)\n",
        "\n",
        "# Load movements_vector.pkl into variable movements_vector\n",
        "with open(os.path.join(folder_path, \"movements_vector.pkl\"), \"rb\") as f:\n",
        "    movements_vector = pickle.load(f)"
      ],
      "metadata": {
        "id": "YLTiO_1EJOmw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tags(user_prompt):\n",
        "    # Split the prompt by commas and strip any leading/trailing whitespace from each tag\n",
        "    tags = [tag.strip() for tag in user_prompt.split(\",\")]\n",
        "    return tags"
      ],
      "metadata": {
        "id": "ppOcenyRJR2M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "def find_similar_artists(input_vector):\n",
        "    most_similar = []\n",
        "    \n",
        "    # Find two most similar tags from top 5 artists_vector\n",
        "    sims_artists = cosine_similarity([input_vector], artists_vector)\n",
        "    sims_artists = sims_artists[0]\n",
        "    # Randomly choose two tags from the top 5 artists\n",
        "    top_artists = [tag_lists['artists'][i] for i in sims_artists.argsort()[-5:][::-1]]\n",
        "    chosen_artists = random.sample(top_artists, k=2)\n",
        "    most_similar.extend(chosen_artists)\n",
        "\n",
        "    return most_similar\n",
        "\n",
        "def find_similar_flavors(input_vector):\n",
        "    most_similar = []\n",
        "\n",
        "    # Find two most similar tags from top 5 flavors_vector\n",
        "    sims_flavors = cosine_similarity([input_vector], flavors_vector)\n",
        "    sims_flavors = sims_flavors[0]\n",
        "    # Randomly choose two tags from the top 5 flavors\n",
        "    top_flavors = [tag_lists['flavors'][i] for i in sims_flavors.argsort()[-5:][::-1]]\n",
        "    chosen_flavors = random.sample(top_flavors, k=2)\n",
        "    most_similar.extend(chosen_flavors)\n",
        "\n",
        "    return most_similar\n",
        "    \n",
        "def find_similar_mediums(input_vector):\n",
        "    most_similar = []\n",
        "\n",
        "    # Find one most similar tag from top 3 medium_vector\n",
        "    sims_medium = cosine_similarity([input_vector], mediums_vector)\n",
        "    sims_medium = sims_medium[0]\n",
        "    # Randomly choose one tag from the top 3 medium\n",
        "    top_mediums = [tag_lists['mediums'][i] for i in sims_medium.argsort()[-3:][::-1]]\n",
        "    chosen_medium = random.choice(top_mediums)\n",
        "    most_similar.append(chosen_medium)\n",
        "\n",
        "    return most_similar\n",
        "    \n",
        "def find_similar_movements(input_vector):\n",
        "    most_similar = []\n",
        "\n",
        "    # Find one most similar tags from top 3 movements_vector\n",
        "    sims_movements = cosine_similarity([input_vector], movements_vector)\n",
        "    sims_movements = sims_movements[0]\n",
        "    # Randomly choose one tag from the top 3 movements\n",
        "    top_movements = [tag_lists['movements'][i] for i in sims_movements.argsort()[-3:][::-1]]\n",
        "    chosen_movement = random.choice(top_movements)\n",
        "    most_similar.append(chosen_movement)\n",
        "    \n",
        "    return most_similar"
      ],
      "metadata": {
        "id": "-UbQo5RfJUKC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorizeUserTags(user_tags):\n",
        "    user_artists = []\n",
        "    user_flavors = []\n",
        "    user_mediums = []\n",
        "    user_movements = []\n",
        "    other_tags = []\n",
        "    artists_list = [tag.lower() for tag in tag_lists[\"artists\"]]\n",
        "    flavors_list = [tag.lower() for tag in tag_lists[\"flavors\"]]\n",
        "    mediums_list = [tag.lower() for tag in tag_lists[\"mediums\"]]\n",
        "    movements_list = [tag.lower() for tag in tag_lists[\"movements\"]]\n",
        "\n",
        "    for tag in user_tags:\n",
        "        if tag in artists_list:\n",
        "            user_artists.append(tag)\n",
        "        elif tag in flavors_list:\n",
        "            user_flavors.append(tag)\n",
        "        elif tag in mediums_list:\n",
        "            user_mediums.append(tag)\n",
        "        elif tag in movements_list:\n",
        "            user_movements.append(tag)\n",
        "        else:\n",
        "            other_tags.append(tag)\n",
        "    \n",
        "    return user_artists, user_flavors, user_mediums, user_movements, other_tags"
      ],
      "metadata": {
        "id": "VRAUY-oDJVX6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAvgTagsVector(tags_list):\n",
        "    tag_vectors = [nlp(tag).vector for tag in tags_list]\n",
        "\n",
        "    avg_vector = sum(tag_vectors) / len(tag_vectors)\n",
        "\n",
        "    return avg_vector"
      ],
      "metadata": {
        "id": "bAurIAmuJWdM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tags(user_prompt):\n",
        "    original_tags = convert_to_tags(user_prompt)\n",
        "    if len(original_tags) < 1:\n",
        "        return \"Prompt too short, please consider addding more details like art style, art medium, lighting, mood, etc.\"\n",
        "\n",
        "    avg_vector = getAvgTagsVector(original_tags)\n",
        "\n",
        "    tags_to_add = []\n",
        "\n",
        "    user_tags = original_tags.copy()[1:]\n",
        "\n",
        "    user_artists, user_flavors, user_mediums, user_movements, other_tags = categorizeUserTags(original_tags.copy())\n",
        "\n",
        "    if len(user_artists) < 2:\n",
        "        most_similar_artists = find_similar_artists(avg_vector)\n",
        "        tags_to_add.extend(most_similar_artists)\n",
        "    if len(user_flavors) < 2:\n",
        "        most_similar_flavors = find_similar_flavors(avg_vector)\n",
        "        tags_to_add.extend(most_similar_flavors)    \n",
        "    if len(user_mediums) < 1:\n",
        "        most_similar_mediums = find_similar_mediums(avg_vector)\n",
        "        tags_to_add.extend(most_similar_mediums)    \n",
        "    if len(user_movements) < 1:\n",
        "        most_similar_movements = find_similar_movements(avg_vector)\n",
        "        tags_to_add.extend(most_similar_movements)\n",
        "\n",
        "\n",
        "    processed_tags = original_tags[:1] + user_artists + user_flavors + user_mediums + user_movements + other_tags + tags_to_add\n",
        "    \n",
        "    # Deduplicate the new tags found\n",
        "    seen = set()\n",
        "    deduplicated_tags = []\n",
        "    for tag in processed_tags:\n",
        "        if tag not in seen:\n",
        "            deduplicated_tags.append(tag)\n",
        "            seen.add(tag)\n",
        "    \n",
        "    # Construct the new prompt\n",
        "    new_prompt =','.join(deduplicated_tags)\n",
        "\n",
        "    return new_prompt"
      ],
      "metadata": {
        "id": "EvobbAdVJXzB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "0GrjKXQfOV0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"mountains and rivers, traditional chinese painting\""
      ],
      "metadata": {
        "id": "0LqWRtFPJZE2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = process_tags(user_prompt)\n",
        "print(new_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e51R8-XJaRm",
        "outputId": "b8edaf39-1ca5-4855-9fd4-d616aa5512c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mountains and rivers,traditional chinese painting,national geographic,Theophanes the Greek,a renaissance painting,arts and crafts movement\n"
          ]
        }
      ]
    }
  ]
}